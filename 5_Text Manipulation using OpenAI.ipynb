{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10fd556",
   "metadata": {},
   "source": [
    "Open AI is a leading organization in the field of Artificial Intelligence and Machine Learning, they have provided the developers with state-of-the-art innovations like ChatGPT, WhisperAI, DALL-E, and many more to work on the vast unstructured data available. For text manipulation, OpenAI has compiled a Completions model which helps you to generate new text data, fill masks in strings, carry conversations, translate, and summarize. The completion module uses the power of GPT-3 to perform these tasks and give out fascinating results. In today‚Äôs article, we will be going through this Completions module and see how one can use this in Python.\n",
    "\n",
    "Steps to perform text manipulation using OpenAI\n",
    "Now let‚Äôs explore how one can use GPT-3 to manipulate text data\n",
    "\n",
    "Step 1: Install the Openai library in your python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c221c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from aiohttp->openai) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\monika201103\\anaconda3\\envs\\torch\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6be6b67",
   "metadata": {},
   "source": [
    "Step 2: Import the openai library and assign the API key to openai environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5a66f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "import openai\n",
    "# assign the API key to the environment by replacing\n",
    "# API_KEY with your generated key\n",
    "openai.api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862a2d2",
   "metadata": {},
   "source": [
    "If you do not have an API key, then log in to your OpenAI account after creating one. After logging in, select Personal from the top-right menu, and then select ‚ÄúView API keys‚Äù. A page containing API keys is displayed, and the button ‚ÄúCreate new secret key‚Äù is visible. A secret key is generated when you click on that, copy it and save it somewhere else because it will be needed in further steps.\n",
    "\n",
    "Step 3: Define a function to perform text manipulation using OpenAI API in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158ec85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in string argument as parameter\n",
    "def comp(PROMPT, MaxToken=50, outputs=3):\n",
    "\t# using OpenAI's Completion module that helps perform\n",
    "\t# text manipulations\n",
    "\tresponse = openai.Completion.create(\n",
    "\t\t# model name used here is text-davinci-003\n",
    "\t\t# there are many other models available under the\n",
    "\t\t# umbrella of GPT-3\n",
    "\t\tmodel=\"text-davinci-003\",\n",
    "\t\t# passing the user input\n",
    "\t\tprompt=PROMPT,\n",
    "\t\t# generated output can have \"max_tokens\" number of tokens\n",
    "\t\tmax_tokens=MaxToken,\n",
    "\t\t# number of outputs generated in one call\n",
    "\t\tn=outputs\n",
    "\t)\n",
    "\t# creating a list to store all the outputs\n",
    "\toutput = list()\n",
    "\tfor k in response['choices']:\n",
    "\t\toutput.append(k['text'].strip())\n",
    "\treturn output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74806604",
   "metadata": {},
   "source": [
    "Here, we have used the Completions module from OpenAI library and generate text for the given user prompt. Here are the important parameters involved with Completions module:\n",
    "\n",
    "1. model [required]: ID of the model to use can find out using the below command \n",
    "2. openai.Model.list().data where the value of ‚Äòid‚Äô represent the model name. we need to select a suitable model as per our use.\n",
    "3. prompt: The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays. Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.\n",
    "4. max_tokens: The maximum number of tokens to generate in the completion. The default value is 16.\n",
    "5. temperature: Sampling temperature ranges between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
    "6. n: number of completions to generate for each prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f52dcc3",
   "metadata": {},
   "source": [
    "# Example prompts for text manipulation\n",
    "Now let‚Äôs try out some prompts with the completions module and see their results.\n",
    "\n",
    "Prompt 1: Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28007a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Negative']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"\"\"Tell me whether the tweet is positive, neutral, or negative.\n",
    "Tweet: I don't like tomato!\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "comp(p, outputs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65210378",
   "metadata": {},
   "source": [
    "Prompt 2: Text Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412f8663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What seems to be the problem?',\n",
       " 'What seems to be the problem?',\n",
       " 'what seems to be the problem?',\n",
       " 'What can I do for you?',\n",
       " 'What can I do to help?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"\"\"hey doctor, ____\"\"\"\n",
    "\n",
    "comp(p,outputs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02246557",
   "metadata": {},
   "source": [
    "Prompt 3: Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd2a3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Walk in Style with _____ Shoes!\"\n",
      "\"Step into Comfort with Our Shoes!\"\n",
      "\"Step up your style with our shoes\"\n"
     ]
    }
   ],
   "source": [
    "p = \"Write a tagline for my shoe company\"\n",
    "Output = comp(p,outputs=3)\n",
    "print(Output[0])\n",
    "print(Output[1])\n",
    "print(Output[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe9ab31",
   "metadata": {},
   "source": [
    "Prompt 4: Text Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b85853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Positive\n",
      "2. Negative\n",
      "3. Positive\n",
      "4. Neutral\n",
      "5. Negative\n"
     ]
    }
   ],
   "source": [
    "p = \"\"\"What is the sentiment of these tweets:\n",
    "\n",
    "1. \"GFG has the best DSA course\"\n",
    "2. \"Got late for work and got fired for that\"\n",
    "3. \"Can't wait for Diwali!!!\"\n",
    "4. \"What do you have in mind?\"\n",
    "5. \"I hate strawberry\"\n",
    "\n",
    "Tweet sentiment ratings:\"\"\"\n",
    "\n",
    "print(comp(p, outputs=1)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45242eea",
   "metadata": {},
   "source": [
    "Prompt 5: Text Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1a5fc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm looking for some good places to eat near here.\n",
      "AI: Sure, I can help you with that! There are some great restaurants nearby. May I suggest a\n",
      "\n",
      " Do you know any good places to eat around here?\n",
      "AI: Of course! There are quite a few great restaurants around here. Depending on what type of food you're\n",
      "\n",
      " Could you suggest some good places to eat near me?\n",
      "AI: Sure! Let's see what I can find. What kind of food are you looking for?\n"
     ]
    }
   ],
   "source": [
    "p=\"\"\"Complete this conversation with an AI assistant.\n",
    "The assistant is helpful, sarcastic, clever, and very nice in nature.\n",
    "Human want to know some good places to eat.\n",
    "\n",
    "Human: Hello, who are you?\n",
    "AI: I am an AI created by OpenAI. How can I help you today?\n",
    "Human:\"\"\"\n",
    "Output = comp(p,MaxToken =35, outputs=3)\n",
    "print(Output[0])\n",
    "print('\\n',Output[1])\n",
    "print('\\n',Output[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb8fd0e",
   "metadata": {},
   "source": [
    "Prompt 6: Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55589296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi: ‡§Æ‡•à‡§Ç GeeksforGeeks ‡§∏‡•á ‡§∏‡•Ä‡§ñ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å‡•§\n",
      "German: Ich lerne von GeeksforGeeks.\n",
      "Japanese: GeeksforGeeks „Åã„ÇâÂ≠¶„Çì„Åß„ÅÑ„Åæ„Åô„ÄÇ\n",
      "\n",
      " Hindi: ‡§Æ‡•à‡§Ç GeeksforGeeks ‡§∏‡•á ‡§∏‡•Ä‡§ñ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å‡•§\n",
      "German: Ich lerne von GeeksforGeeks.\n",
      "Japanese: ÁßÅ„ÅØGeeksforGeeks„Åã„ÇâÂ≠¶„Çì„Åß„ÅÑ„Åæ„Åô„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "p=\"\"\"\n",
    "Translate this sentence in hindi, german and japanese:\n",
    "'I am learning from GeeksforGeeks.'\n",
    "\"\"\"\n",
    "Output = comp(p,MaxToken=500,outputs=2)\n",
    "print(Output[0])\n",
    "print('\\n',Output[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac549966",
   "metadata": {},
   "source": [
    "Prompt 7: Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18bd5698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mount Everest is the highest mountain in the world and an exciting place to visit, but it is\n",
      "Mt. Everest is the tallest mountain in the world and lots of people try to climb it\n",
      "Mt. Everest is a very tall mountain in the Himalayas that is very dangerous to\n"
     ]
    }
   ],
   "source": [
    "p=\"\"\"\n",
    "Summarize the below paragraph for a pre-school student explaining\n",
    "how dangerous Mt. Everest is:\n",
    "\n",
    "Mount Everest, located in the Himalayas, is the highest\n",
    "peak in the world and a popular destination for mountaineers.\n",
    "Standing at an impressive elevation of 29,029 feet (8,848 meters),\n",
    "it poses a significant challenge to climbers due to its extreme\n",
    "altitude and unpredictable weather conditions. The mountain is\n",
    "situated on the border between Nepal and China, and it attracts\n",
    "adventurers from around the globe who are determined to conquer\n",
    "its formidable slopes. Mount Everest has a rich history of expeditions\n",
    "and has been a subject of fascination for explorers and adventurers\n",
    "for centuries. Despite its allure, scaling Mount Everest is a\n",
    "dangerous undertaking that requires meticulous planning, physical\n",
    "fitness, and mountaineering expertise.\n",
    "\"\"\"\n",
    "Output = comp(p,MaxToken=20,outputs=3)\n",
    "print(Output[0])\n",
    "print(Output[1])\n",
    "print(Output[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9df54ab",
   "metadata": {},
   "source": [
    "Prompt 8: Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a36b1eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§Æ‡§æ‡§â‡§Ç‡§ü ‡§è‡§µ‡§∞‡•á‡§∏‡•ç‡§ü, ‡§ù‡§Æ‡•á‡§≤‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§•‡§ø‡§§ ‡§π‡•à, ‡§Ø‡§π ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§∏‡§∞‡•ç‡§µ‡§æ‡§ß‡§ø‡§ï ‡§ä‡§Å‡§ö‡•á ‡§™‡§∞‡•ç‡§µ‡§§ ‡§π‡•à ‡§î‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£ ‡§Ø‡§æ‡§§‡•ç‡§∞‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§ó‡§Ç‡§§‡§µ‡•ç‡§Ø ‡§π‡•à‡•§ 29,029 ‡§´‡•Ä‡§ü (8,848 ‡§Æ‡•Ä‡§ü‡§∞) ‡§ï‡•Ä ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ï ‡§ä‡§Å‡§ö‡§æ‡§à ‡§ï‡•á ‡§∏‡§æ‡§•, ‡§Ø‡§π ‡§è‡§ï ‡§ó‡§π‡§∞‡•Ä ‡§ö‡•Å‡§®‡•å‡§§‡•Ä ‡§â‡§†‡§æ‡§§‡§æ ‡§π‡•à ‡§Ö‡§™‡§®‡•á ‡§Ö‡§§‡•ç‡§Ø‡§ß‡§ø‡§ï ‡§ä‡§Å‡§ö‡§æ‡§à ‡§î‡§∞ ‡§Ö‡§®‡§™‡•á‡§ï‡•ç‡§∑‡§ø‡§§ ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•Ä ‡§∂‡§∞‡•ç‡§§‡•ã‡§Ç ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£‡•§ ‡§Ø‡§π ‡§™‡§∞‡•ç‡§µ‡§§ ‡§®‡•á‡§™‡§æ‡§≤ ‡§î‡§∞ ‡§ö‡•Ä‡§® ‡§ï‡•á ‡§∏‡•Ä‡§Æ‡§æ ‡§™‡§∞ ‡§∏‡•ç‡§•‡§ø‡§§ ‡§π‡•à ‡§î‡§∞ ‡§Ø‡§π ‡§µ‡§ø‡§∂‡•ç‡§µ ‡§ï‡•á ‡§ó‡•Å‡§´‡§æ‡§ì‡§Ç ‡§∏‡•á ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§™‡•ç‡§∞‡§µ‡§æ‡§∏‡•Ä ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ø‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§ú‡•ã ‡§á‡§∏‡§ï‡•á ‡§¶‡•Å‡§∞‡•ç‡§¶‡§Æ‡•ç‡§Ø ‡§™‡§π‡§æ‡§°‡§º‡•ã‡§Ç ‡§ï‡•ã ‡§Ö‡§ß‡§ø‡§ï‡•É‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§π‡•à‡§Ç‡•§ ‡§Æ‡§æ‡§â‡§Ç‡§ü ‡§è‡§µ‡§∞‡•á‡§∏‡•ç‡§ü ‡§ï‡§æ ‡§è‡§ï ‡§Ö‡§®‡•Å‡§≠‡§µ‡•Ä ‡§Ø‡§æ‡§§‡•ç‡§∞‡§æ ‡§ï‡§æ ‡§ó‡§π‡§∞‡§æ ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§π‡•à ‡§î‡§∞ ‡§Ø‡§π ‡§∏‡•á‡§≤‡•ç‡§∏ ‡§î‡§∞ ‡§µ‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§®‡§æ‡§§‡§ø‡§•‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§£ ‡§µ‡§ø‡§∑‡§Ø ‡§∞‡§π‡§æ ‡§π‡•à ‡§∏‡§¶‡•Ä‡§Ø‡§æ‡§Ç ‡§¨‡§æ‡§¶‡•§ ‡§Ö‡§≤‡•ç‡§™‡§µ‡§ø‡§∞‡§æ‡§Æ ‡§ï‡•á ‡§¨‡§æ‡§µ‡§ú‡•Ç‡§¶, ‡§Æ‡§æ‡§â‡§Ç‡§ü ‡§è‡§µ‡§∞‡•á‡§∏‡•ç‡§ü ‡§ï‡•ã ‡§Ö‡§ó‡•ç‡§∞‡§§‡§æ‡§™‡§∞‡•ç‡§®‡§æ ‡§è‡§ï ‡§ñ‡§§‡§∞‡§®‡§æ‡§ï ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§π‡•à ‡§ú‡•ã ‡§§‡§™‡§® ‡§î‡§∞ ‡§Ü‡§∞‡•ç‡§•‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§®‡•á, ‡§´‡§ø‡§ú‡§ø‡§ï‡§≤ ‡§´‡§ø‡§ü‡§®‡•á‡§∏ ‡§î‡§∞ ‡§™‡§∞‡•ç‡§µ‡§§‡§æ‡§∞‡•ã‡§π‡§£ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï‡§§‡§æ ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§\n"
     ]
    }
   ],
   "source": [
    "p=\"\"\"\n",
    "How would Indian say this paragraph:\n",
    "\n",
    "Mount Everest, located in the Himalayas, is the highest\n",
    "peak in the world and a popular destination for mountaineers.\n",
    "Standing at an impressive elevation of 29,029 feet (8,848 meters),\n",
    "it poses a significant challenge to climbers due to its extreme\n",
    "altitude and unpredictable weather conditions. The mountain is\n",
    "situated on the border between Nepal and China, and it attracts\n",
    "adventurers from around the globe who are determined to conquer\n",
    "its formidable slopes. Mount Everest has a rich history of expeditions\n",
    "and has been a subject of fascination for explorers and adventurers\n",
    "for centuries. Despite its allure, scaling Mount Everest is a\n",
    "dangerous undertaking that requires meticulous planning, physical\n",
    "fitness, and mountaineering expertise.\n",
    "\"\"\"\n",
    "Output = comp(p,MaxToken=1200,outputs=1)\n",
    "print(Output[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf96789f",
   "metadata": {},
   "source": [
    "Prompt 9: Text Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd51e8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. üó£Ô∏è\n",
      "2. ü§ì\n",
      "3. ‚û°Ô∏è\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Convert the below text to emoji's\n",
    "Text:###\n",
    "1. Hi\n",
    "2. Geeks\n",
    "3. For\n",
    "###\n",
    "Answer:\n",
    "\"\"\"\n",
    "print(comp(PROMPT, MaxToken=300, outputs=1)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52bd0ce",
   "metadata": {},
   "source": [
    "Prompt 10: Text Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93e0622e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úã‚ú®ü§ìüîÅ\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Convert the below text to only special characters\n",
    "Text:###\n",
    "1. Hi\n",
    "2. Geeks\n",
    "3. For\n",
    "###\n",
    "Answer:\n",
    "\"\"\"\n",
    "print(comp(PROMPT, MaxToken=300, outputs=1)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273046e6",
   "metadata": {},
   "source": [
    "Prompt 11: Retrieve factual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b87b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 28 states and 8 union territories in India.\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "How many states are in India?\n",
    "Answer:\n",
    "\"\"\"\n",
    "print(comp(PROMPT, MaxToken=300, outputs=1)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb586c",
   "metadata": {},
   "source": [
    "Prompt 12: Retrieve factual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be39792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 195 countries in the world.\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "How many countries are there in world?\n",
    "Answer:\n",
    "\"\"\"\n",
    "print(comp(PROMPT, MaxToken=300, outputs=1)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8678a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of chocolate burfis is 9 x 50 + 25 = 475.\n",
      "To pack 475 chocolate burfis in boxes of 12 requires 40 boxes. The 5 burfis left can't be packed.\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "There are 9 trays with 50 chocolate burfi in each and one more tray with 25 chocolate burfi which has to be packed in boxes of 12. \n",
    "Find the number of boxes required to pack chocolate burfis equally and how many chocolate burfis are left\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "print(comp(PROMPT, MaxToken=300, outputs=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7506468",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

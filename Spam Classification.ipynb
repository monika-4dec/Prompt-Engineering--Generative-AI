{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed51090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #mandatory\n",
    "import openai"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f0f3224",
   "metadata": {},
   "source": [
    "def message_and_history(input, history):\n",
    "\thistory = history or []\n",
    "\tprint(history)\n",
    "\ts = list(sum(history, ()))\n",
    "\tprint(s)\n",
    "\ts.append(input)\n",
    "\tprint('#########################################')\n",
    "\tprint(s)\n",
    "\tinp = ' '.join(s)\n",
    "\tprint(inp)\n",
    "\toutput = api_calling(inp)\n",
    "\thistory.append((input, output))\n",
    "\tprint('------------------')\n",
    "\tprint(history)\n",
    "\tprint(history)\n",
    "\tprint(\"*********************\")\n",
    "\treturn history, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59007a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing openai module\n",
    "import openai\n",
    "# assigning API KEY to the variable\n",
    "\n",
    "openai.api_key = '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'\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dedc2a1c",
   "metadata": {},
   "source": [
    "# necessary libraries\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# libraries to develop and evaluate a machine learning model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2945a32",
   "metadata": {},
   "source": [
    "# Temperature:\n",
    "Temperature is a hyperparameter that controls the randomness of the generated text. A lower temperature leads to more conservative and predictable output, while a higher temperature leads to more diverse and unexpected output. When the temperature is low, the model tends to choose the most probable next word, while a higher temperature leads to more exploration of alternative options.\n",
    "\n",
    "# Top-p:\n",
    "Top-p, also known as nucleus sampling, is a technique used in language models to generate diverse and coherent output. It works by selecting the top-k most probable words from the model’s output distribution, where k is dynamically determined based on a probability threshold p. The threshold p determines the cumulative probability of the selected words, ensuring that the generated text is coherent and grammatically correct.\n",
    "\n",
    "# Presence Penalty:\n",
    "Presence penalty is the method used to ensure that GPT-3 doesn’t use repeated phrases or ideas. In this context, Presence Penalty will reduce the probability of the next generated token’s appearance in the final output. Presence penalty is particularly useful in text generation that requires novelty or creativity, such as creative writing or advertising.\n",
    "\n",
    "# Frequency Penalty:\n",
    "Finally, Frequency Penalty in GPT-3 plays a similar role to Presence Penalty but instead restricts the language model’s output to less common phrases or words. This metric is useful in generating novel and impressive sentences that the average writer would never dream of. Frequency Penalty can be particularly helpful when tasked with writing advertising copy or delivering a critical message in a high-stakes scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c5a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_classification(message):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=f\"Classify the following message as spam or not spam:\\n\\n{message}\\n\\nAnswer:\",\n",
    "        temperature=0,\n",
    "        max_tokens=64,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    return response['choices'][0]['text'].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6b70a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam\n"
     ]
    }
   ],
   "source": [
    "out = spam_classification(\"\"\"Congratulations! You've Won a $1000 gift card from walmart.Go to https://bit.ly to claim your reward.\"\"\")\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96af8b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not spam\n"
     ]
    }
   ],
   "source": [
    "out = spam_classification(\"Hey Alex, just wanted to let you know tomorrow is an off. Thank you\")\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2645c9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
